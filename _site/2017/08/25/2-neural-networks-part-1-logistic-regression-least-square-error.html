<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>2. Neural Networks Part 1: Logistic Regression (Least Square Error)</title>
  <link href="/fonts.css" rel="stylesheet" charset="utf-8">
  <link rel="stylesheet" href="/style.css">
  <!-- Begin Jekyll SEO tag v2.3.0 -->
<title>Neural Networks Part 1: Logistic Regression (Least Square Error) | Rakesh Malviya</title>
<meta property="og:title" content="Neural Networks Part 1: Logistic Regression (Least Square Error)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Required Learning: Linear regression basics link We are starting from basic unit of Neural networks single activation neuron. A Neural network with single neuron is same as logistic regression. Therefore a neural network can be considered as a networked set of logistic regression units. Establish notations for future use1 to denote the ith “input ” of training data to denote the ith “output” or target of training data Pair is called a training example The dataset that we’ll be using to learn—a list of m training examples — is called a training set Each in training set can have features such that is a vector In current setup of logistic regression is scalar value Note that the superscript “(i)” in the notation is simply an index into the training set, and has nothing to do with exponentiation. Fig: Single neuron Let , where is predicted output is activation function , for training example, where is bias of the neuron. weights or training parameters we need to learn We will apply gradient descent to minimize the squared error cost function , also called least square error \begin{align} J = \frac{1}{2m}\sum_{i=1}^{m} (y^{(i)} - y’^{(i)})^2 \tag{1} \label{eq1} \end{align} Note: term in makes the derivative of J much simpler as you will see later. With in loss function value does not depend on the size of training data i.e. which makes it easy for comparison for different values of or batch size in case of mini-batch stochatic gradient that you will see later sections. We will use Sigmoid function as activation function, i.e. \begin{align} \sigma(u^{(i)}) = \dfrac{1}{1+e^{-u^{(i)}}} = f(u^{(i)}) = y’^{(i)} \tag{2} \label{eq2} \end{align} Derivatives \begin{align} \frac{\partial\sigma(u)}{\partial{u}} = \sigma(u)\cdot(1 - \sigma(u)) \tag{3} \label{eq3} \end{align} \begin{align} \frac{\partial{J}}{\partial{y’^{(i)}}} = y’^{(i)} - y^{(i)} \tag{4} \label{eq4} \end{align} \begin{align} \frac{\partial{u^{(i)}}}{\partial{w_j}} = x_j^{(i)} \tag{5} \label{eq5} \end{align} \begin{align} \frac{\partial{u^{(i)}}}{\partial{b}} = 1 \tag{6} \label{eq6} \end{align} Gradient Descent To learn and parameter so that is minimum. We will find and Note: is our loss function and is for indexing Since, is function of , is function of and is function of by . Using chain rule of differentiation Note: Sum () and averaging ()of gradient is needed for following reasons: Summing of individual gradients on training examples makes gradient update smoother Without averaging the learning rate depends on the size of training data or batch size With averaging the gradient magnitude is independent of the batch size. This allows comparison when using different batch sizes or training data size . So during the training update equation for over all is as follows: Similarly: Update equation for bias is as follows: Training Steps: Choose an initial vector of parameters , bias and learning rate . Repeat for predifined epoch such that approximate minimum loss is obtained: Evaluate and store for all training examples by using equation Update bias, For in : Update, Code snippet of above steps: #Accumulate gradient with respect to bias and weights grad_bias = 0 grad_w = np.zeros(len(W)) for i in range(X_train.shape[0]): grad_bias += (YP[i] - y_train[i])*(YP[i])*(1-YP[i]) #dJ/db for j in range(len(W)): #dJ/dW_j grad_w[j] += (YP[i] - y_train[i])*(YP[i])*(1-YP[i])*(X_train[i][j]) #Update bias bias = bias - grad_bias*lr/X_train.shape[0] #Update weights for j in range(len(W)): W[j] = W[j] - grad_w[j]*lr/X_train.shape[0] Code Here is the python implementation of the above article. Stochastic gradient descent, SGD When training data size is large we choose of batch size. We divide our training data into batches of size . We update weights and bias for each batch as follows: Choose an initial vector of parameters , bias and learning rate . Divide training data into batches of size Repeat for predifined epoch such that approximate minimum loss is obtained: Repeat for each batch: Evaluate and store for all training examples by using equation Update bias, For in : Update, Advantages of SGD Much faster than normal gradient descent Better choice when whole training data cannot fit into the RAM (available memory) of the system References: http://cs229.stanford.edu/notes Previous Posts: “1. Word2vec Part 1: Basics”" />
<meta property="og:description" content="Required Learning: Linear regression basics link We are starting from basic unit of Neural networks single activation neuron. A Neural network with single neuron is same as logistic regression. Therefore a neural network can be considered as a networked set of logistic regression units. Establish notations for future use1 to denote the ith “input ” of training data to denote the ith “output” or target of training data Pair is called a training example The dataset that we’ll be using to learn—a list of m training examples — is called a training set Each in training set can have features such that is a vector In current setup of logistic regression is scalar value Note that the superscript “(i)” in the notation is simply an index into the training set, and has nothing to do with exponentiation. Fig: Single neuron Let , where is predicted output is activation function , for training example, where is bias of the neuron. weights or training parameters we need to learn We will apply gradient descent to minimize the squared error cost function , also called least square error \begin{align} J = \frac{1}{2m}\sum_{i=1}^{m} (y^{(i)} - y’^{(i)})^2 \tag{1} \label{eq1} \end{align} Note: term in makes the derivative of J much simpler as you will see later. With in loss function value does not depend on the size of training data i.e. which makes it easy for comparison for different values of or batch size in case of mini-batch stochatic gradient that you will see later sections. We will use Sigmoid function as activation function, i.e. \begin{align} \sigma(u^{(i)}) = \dfrac{1}{1+e^{-u^{(i)}}} = f(u^{(i)}) = y’^{(i)} \tag{2} \label{eq2} \end{align} Derivatives \begin{align} \frac{\partial\sigma(u)}{\partial{u}} = \sigma(u)\cdot(1 - \sigma(u)) \tag{3} \label{eq3} \end{align} \begin{align} \frac{\partial{J}}{\partial{y’^{(i)}}} = y’^{(i)} - y^{(i)} \tag{4} \label{eq4} \end{align} \begin{align} \frac{\partial{u^{(i)}}}{\partial{w_j}} = x_j^{(i)} \tag{5} \label{eq5} \end{align} \begin{align} \frac{\partial{u^{(i)}}}{\partial{b}} = 1 \tag{6} \label{eq6} \end{align} Gradient Descent To learn and parameter so that is minimum. We will find and Note: is our loss function and is for indexing Since, is function of , is function of and is function of by . Using chain rule of differentiation Note: Sum () and averaging ()of gradient is needed for following reasons: Summing of individual gradients on training examples makes gradient update smoother Without averaging the learning rate depends on the size of training data or batch size With averaging the gradient magnitude is independent of the batch size. This allows comparison when using different batch sizes or training data size . So during the training update equation for over all is as follows: Similarly: Update equation for bias is as follows: Training Steps: Choose an initial vector of parameters , bias and learning rate . Repeat for predifined epoch such that approximate minimum loss is obtained: Evaluate and store for all training examples by using equation Update bias, For in : Update, Code snippet of above steps: #Accumulate gradient with respect to bias and weights grad_bias = 0 grad_w = np.zeros(len(W)) for i in range(X_train.shape[0]): grad_bias += (YP[i] - y_train[i])*(YP[i])*(1-YP[i]) #dJ/db for j in range(len(W)): #dJ/dW_j grad_w[j] += (YP[i] - y_train[i])*(YP[i])*(1-YP[i])*(X_train[i][j]) #Update bias bias = bias - grad_bias*lr/X_train.shape[0] #Update weights for j in range(len(W)): W[j] = W[j] - grad_w[j]*lr/X_train.shape[0] Code Here is the python implementation of the above article. Stochastic gradient descent, SGD When training data size is large we choose of batch size. We divide our training data into batches of size . We update weights and bias for each batch as follows: Choose an initial vector of parameters , bias and learning rate . Divide training data into batches of size Repeat for predifined epoch such that approximate minimum loss is obtained: Repeat for each batch: Evaluate and store for all training examples by using equation Update bias, For in : Update, Advantages of SGD Much faster than normal gradient descent Better choice when whole training data cannot fit into the RAM (available memory) of the system References: http://cs229.stanford.edu/notes Previous Posts: “1. Word2vec Part 1: Basics”" />
<link rel="canonical" href="http://localhost:4000/2017/08/25/2-neural-networks-part-1-logistic-regression-least-square-error.html" />
<meta property="og:url" content="http://localhost:4000/2017/08/25/2-neural-networks-part-1-logistic-regression-least-square-error.html" />
<meta property="og:site_name" content="Rakesh Malviya" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-08-25T00:00:00+05:30" />
<script type="application/ld+json">
{"name":null,"description":"Required Learning: Linear regression basics link We are starting from basic unit of Neural networks single activation neuron. A Neural network with single neuron is same as logistic regression. Therefore a neural network can be considered as a networked set of logistic regression units. Establish notations for future use1 to denote the ith “input ” of training data to denote the ith “output” or target of training data Pair is called a training example The dataset that we’ll be using to learn—a list of m training examples — is called a training set Each in training set can have features such that is a vector In current setup of logistic regression is scalar value Note that the superscript “(i)” in the notation is simply an index into the training set, and has nothing to do with exponentiation. Fig: Single neuron Let , where is predicted output is activation function , for training example, where is bias of the neuron. weights or training parameters we need to learn We will apply gradient descent to minimize the squared error cost function , also called least square error \\begin{align} J = \\frac{1}{2m}\\sum_{i=1}^{m} (y^{(i)} - y’^{(i)})^2 \\tag{1} \\label{eq1} \\end{align} Note: term in makes the derivative of J much simpler as you will see later. With in loss function value does not depend on the size of training data i.e. which makes it easy for comparison for different values of or batch size in case of mini-batch stochatic gradient that you will see later sections. We will use Sigmoid function as activation function, i.e. \\begin{align} \\sigma(u^{(i)}) = \\dfrac{1}{1+e^{-u^{(i)}}} = f(u^{(i)}) = y’^{(i)} \\tag{2} \\label{eq2} \\end{align} Derivatives \\begin{align} \\frac{\\partial\\sigma(u)}{\\partial{u}} = \\sigma(u)\\cdot(1 - \\sigma(u)) \\tag{3} \\label{eq3} \\end{align} \\begin{align} \\frac{\\partial{J}}{\\partial{y’^{(i)}}} = y’^{(i)} - y^{(i)} \\tag{4} \\label{eq4} \\end{align} \\begin{align} \\frac{\\partial{u^{(i)}}}{\\partial{w_j}} = x_j^{(i)} \\tag{5} \\label{eq5} \\end{align} \\begin{align} \\frac{\\partial{u^{(i)}}}{\\partial{b}} = 1 \\tag{6} \\label{eq6} \\end{align} Gradient Descent To learn and parameter so that is minimum. We will find and Note: is our loss function and is for indexing Since, is function of , is function of and is function of by . Using chain rule of differentiation Note: Sum () and averaging ()of gradient is needed for following reasons: Summing of individual gradients on training examples makes gradient update smoother Without averaging the learning rate depends on the size of training data or batch size With averaging the gradient magnitude is independent of the batch size. This allows comparison when using different batch sizes or training data size . So during the training update equation for over all is as follows: Similarly: Update equation for bias is as follows: Training Steps: Choose an initial vector of parameters , bias and learning rate . Repeat for predifined epoch such that approximate minimum loss is obtained: Evaluate and store for all training examples by using equation Update bias, For in : Update, Code snippet of above steps: #Accumulate gradient with respect to bias and weights grad_bias = 0 grad_w = np.zeros(len(W)) for i in range(X_train.shape[0]): grad_bias += (YP[i] - y_train[i])*(YP[i])*(1-YP[i]) #dJ/db for j in range(len(W)): #dJ/dW_j grad_w[j] += (YP[i] - y_train[i])*(YP[i])*(1-YP[i])*(X_train[i][j]) #Update bias bias = bias - grad_bias*lr/X_train.shape[0] #Update weights for j in range(len(W)): W[j] = W[j] - grad_w[j]*lr/X_train.shape[0] Code Here is the python implementation of the above article. Stochastic gradient descent, SGD When training data size is large we choose of batch size. We divide our training data into batches of size . We update weights and bias for each batch as follows: Choose an initial vector of parameters , bias and learning rate . Divide training data into batches of size Repeat for predifined epoch such that approximate minimum loss is obtained: Repeat for each batch: Evaluate and store for all training examples by using equation Update bias, For in : Update, Advantages of SGD Much faster than normal gradient descent Better choice when whole training data cannot fit into the RAM (available memory) of the system References: http://cs229.stanford.edu/notes Previous Posts: “1. Word2vec Part 1: Basics”","author":null,"@type":"BlogPosting","url":"http://localhost:4000/2017/08/25/2-neural-networks-part-1-logistic-regression-least-square-error.html","image":null,"publisher":null,"headline":"Neural Networks Part 1: Logistic Regression (Least Square Error)","dateModified":"2017-08-25T00:00:00+05:30","datePublished":"2017-08-25T00:00:00+05:30","sameAs":null,"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2017/08/25/2-neural-networks-part-1-logistic-regression-least-square-error.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>
<body>
  <div class="container_post">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<header class="masthead">
  <h1 class="masthead-title--small">
    <a href="/">Rakesh Malviya</a>
  </h1>
</header>      
<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.10";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
        <div class="fb-share-button" data-href="/2017/08/25/2-neural-networks-part-1-logistic-regression-least-square-error.html" data-layout="button_count" data-size="small" data-mobile-iframe="true"><a class="fb-xfbml-parse-ignore" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdevelopers.facebook.com%2Fdocs%2Fplugins%2F&amp;src=sdkpreparse">Share</a></div>

        <a href="https://twitter.com/share" class="twitter-share-button" data-show-count="false">Tweet</a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

        <!-- Place this tag in your head or just before your close body tag. -->
        <script src="https://apis.google.com/js/platform.js" async defer></script>
        <!-- Place this tag where you want the share button to render. -->
        <div class="g-plus" data-action="share"></div>
        <hr/>

<div class="content post">
  <h1 class="post-title">2. Neural Networks Part 1: Logistic Regression (Least Square Error)</h1>
  <div class="meta_wrapper">
  <span class="post-date">25 Aug 2017</span>
  
  
    <a href="/tags#neural-networks" class="post-tag">Neural Networks</a>
  
    <a href="/tags#machine-learning" class="post-tag">Machine Learning</a>
  
    <a href="/tags#deep-learning" class="post-tag">Deep Learning</a>
  
  
<div class="meta_wrapper">  
  <p>Required Learning: Linear regression basics <a href="http://www.holehouse.org/mlclass/01_02_Introduction_regression_analysis_and_gr.html">link</a></p>

<p>We are starting from basic unit of Neural networks single activation neuron. A Neural network with single neuron is same as logistic regression. Therefore a neural network can be considered as a networked set of logistic regression units.</p>

<h4 id="establish-notations-for-future-use1">Establish notations for future use<sup><a href="#references">1</a></sup></h4>
<ol>
  <li><script type="math/tex">x^{(i)}</script> to denote the i<sup>th</sup> “input ” of training data</li>
  <li><script type="math/tex">y^{(i)}</script> to denote the i<sup>th</sup> “output” or target of training data</li>
  <li>Pair <script type="math/tex">(x^{(i)}, y^{(i)})</script> is called a training example</li>
  <li>The dataset that we’ll be using to learn—a list of m training examples <script type="math/tex">\{(x(i), y(i)); i = 1, . . . , m\}</script> — is called a training set</li>
  <li>Each <script type="math/tex">x^{(i)}</script> in training set can have <script type="math/tex">n</script> <strong>features</strong> such that <script type="math/tex">x^{(i)}</script> is a vector <script type="math/tex">(x^{(i)}_1,x^{(i)}_2,x^{(i)}_3,..... x^{(i)}_n)</script></li>
  <li>In current setup of logistic regression <script type="math/tex">y^{(i)}</script> is scalar value</li>
</ol>

<p><strong>Note that the superscript “(i)” in the notation is simply an index into the training set, and has nothing to do with exponentiation.</strong></p>

<p><img src="/assets/img/blog/2/2_1_logistic_reg.svg" alt="" title="Single neuron" />
<i><center>Fig: Single neuron</center></i></p>

<p>Let <script type="math/tex">y'^{(i)} = f(u^{(i)})</script> , 
where</p>
<ol>
  <li><script type="math/tex">y'^{(i)}</script> is predicted output</li>
  <li><script type="math/tex">f</script> is activation function</li>
  <li><script type="math/tex">u^{(i)} = {b} + \sum_{j=1}^{n} {w_j}\cdot{x_j^{(i)}}</script>, for <script type="math/tex">i^{th}</script> training example, where <script type="math/tex">b</script> is bias of the neuron.</li>
  <li><script type="math/tex">w_j</script> <strong>weights</strong> or <strong>training parameters</strong> we need to learn</li>
</ol>

<p>We will apply gradient descent to minimize the squared error cost function <script type="math/tex">J</script>, also called least square error</p>

<p>\begin{align}
J = \frac{1}{2m}\sum_{i=1}^{m} (y^{(i)} - y’^{(i)})^2 \tag{1} \label{eq1}
\end{align}</p>

<p><strong>Note:</strong> term <script type="math/tex">2</script> in <script type="math/tex">\frac{1}{2m}</script> makes the derivative of J much simpler as you will see later. With <script type="math/tex">m</script> in <script type="math/tex">\frac{1}{2m}</script> loss function value <script type="math/tex">J</script> does not depend on the size of training data i.e. <script type="math/tex">m</script> which makes it easy for comparison for different values of <script type="math/tex">m</script> or batch size in case of <strong>mini-batch stochatic gradient</strong> that you will see later sections.</p>

<p>We will use Sigmoid function as activation function, i.e. <script type="math/tex">\sigma(u)</script>
\begin{align}
\sigma(u^{(i)}) = \dfrac{1}{1+e^{-u^{(i)}}} = f(u^{(i)}) = y’^{(i)}   \tag{2} \label{eq2}
\end{align}</p>

<h4 id="derivatives">Derivatives</h4>

<p>\begin{align}
\frac{\partial\sigma(u)}{\partial{u}} = \sigma(u)\cdot(1 - \sigma(u))   \tag{3} \label{eq3}
\end{align}
\begin{align}
\frac{\partial{J}}{\partial{y’^{(i)}}} = y’^{(i)} - y^{(i)}   \tag{4} \label{eq4}
\end{align}
\begin{align}
\frac{\partial{u^{(i)}}}{\partial{w_j}} = x_j^{(i)}   \tag{5} \label{eq5}
\end{align}
\begin{align}
\frac{\partial{u^{(i)}}}{\partial{b}} = 1   \tag{6} \label{eq6}
\end{align}</p>

<h4 id="gradient-descent">Gradient Descent</h4>

<p>To learn <script type="math/tex">w_j</script> and <script type="math/tex">b</script> parameter so that <script type="math/tex">J</script> is minimum. We will find <script type="math/tex">\frac{\partial{J}}{\partial{w_j}}</script> and <script type="math/tex">\frac{\partial{J}}{\partial{b}}</script></p>

<p><strong>Note: <script type="math/tex">J</script> is our loss function and <script type="math/tex">j</script> is for indexing</strong></p>

<p>Since, <script type="math/tex">J</script> is function of <script type="math/tex">y'^{(i)}</script>, <script type="math/tex">y'^{(i)}</script> is function of <script type="math/tex">u^{(i)}</script> and <script type="math/tex">u^{(i)}</script> is function of <script type="math/tex">w_j</script> by <script type="math/tex">\eqref{eq1} and \eqref{eq2}</script>. Using chain rule of differentiation</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align} 
\frac{\partial{J}}{\partial{w_j}} &= \frac{1}{m}\sum_{i=1}^{m}  \frac{\partial{J}}{\partial{y'^{(i)}}} \cdot  \frac{\partial{y'^{(i)}}}{\partial{w_j}}   && \text{by \eqref{eq1}} \\
&= \frac{1}{m}\sum_{i=1}^{m}  \frac{\partial{J}}{\partial{y'^{(i)}}} \cdot  \frac{\partial{y'^{(i)}}}{\partial{u^{(i)}}} \cdot    \frac{\partial{u^{(i)}}}{\partial{w_j}}  \\
&= \frac{1}{m}\sum_{i=1}^{m}  (y'^{(i)} - y^{(i)}) \cdot  \frac{\partial{y'^{(i)}}}{\partial{u^{(i)}}} \cdot    \frac{\partial{u^{(i)}}}{\partial{w_j}}  && \text{by \eqref{eq4}} \\
&= \frac{1}{m}\sum_{i=1}^{m}  (y'^{(i)} - y^{(i)}) \cdot  y'^{(i)} \cdot (1 - y'^{(i)}) \cdot    \frac{\partial{u^{(i)}}}{\partial{w_j}}  && \text{by \eqref{eq2} and \eqref{eq3}} \\
\frac{\partial{J}}{\partial{w_j}} &= \frac{1}{m}\sum_{i=1}^{m}  (y'^{(i)} - y^{(i)}) \cdot  y'^{(i)} \cdot (1 - y'^{(i)}) \cdot  x_j^{(i)} && \text{by \eqref{eq5}} \tag{7} \label{eq7}
\end{align} %]]></script>

<p><strong>Note:</strong> Sum (<script type="math/tex">\sum_{i=1}^{m}</script>) and averaging (<script type="math/tex">\frac{1}{m}</script>)of gradient is needed for following reasons:</p>
<ol>
  <li>Summing of individual gradients on training examples makes gradient update smoother</li>
  <li>Without averaging the learning rate depends on the size of training data <script type="math/tex">m</script> or batch size</li>
  <li>With averaging the gradient magnitude is independent of the batch size. This allows comparison when using different batch sizes or training data size <script type="math/tex">m</script>.</li>
</ol>

<p>So during the training update equation for <script type="math/tex">w_j</script> over all <script type="math/tex">j = 1 ..... n</script> is as follows:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align} 
w_j &= w_j - \eta \cdot \frac{\partial{J}}{\partial{w_j}} \\
&= w_j - \eta \cdot  \frac{1}{m}\sum_{i=1}^{m}  (y'^{(i)} - y^{(i)}) \cdot  y'^{(i)} \cdot (1 - y'^{(i)}) \cdot  x_j^{(i)} && \text{by \eqref{eq7}}
\end{align} %]]></script>

<p>Similarly:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align} 
\frac{\partial{J}}{\partial{b}} &=  \frac{1}{m}\sum_{i=1}^{m}  \frac{\partial{J}}{\partial{y'^{(i)}}} \cdot  \frac{\partial{y'^{(i)}}}{\partial{b}}   && \text{by \eqref{eq1}} \\
&=  \frac{1}{m}\sum_{i=1}^{m}  \frac{\partial{J}}{\partial{y'^{(i)}}} \cdot  \frac{\partial{y'^{(i)}}}{\partial{u^{(i)}}} \cdot    \frac{\partial{u^{(i)}}}{\partial{b}}  \\
&=  \frac{1}{m}\sum_{i=1}^{m}  (y'^{(i)} - y^{(i)}) \cdot  \frac{\partial{y'^{(i)}}}{\partial{u^{(i)}}} \cdot    \frac{\partial{u^{(i)}}}{\partial{b}}  && \text{by \eqref{eq4}} \\
&=  \frac{1}{m}\sum_{i=1}^{m}  (y'^{(i)} - y^{(i)}) \cdot  y'^{(i)} \cdot (1 - y'^{(i)}) \cdot    \frac{\partial{u^{(i)}}}{\partial{b}}  && \text{by \eqref{eq2} and \eqref{eq3}} \\
\frac{\partial{J}}{\partial{b}} &=  \frac{1}{m}\sum_{i=1}^{m}  (y'^{(i)} - y^{(i)}) \cdot  y'^{(i)} \cdot (1 - y'^{(i)}) && \text{by \eqref{eq6}} \tag{8} \label{eq8}
\end{align} %]]></script>

<p>Update equation for bias <script type="math/tex">b</script> is as follows:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align} 
b &= b - \eta \cdot \frac{\partial{J}}{\partial{b}} \\
&= b - \eta \cdot  \frac{1}{m}\sum_{i=1}^{m}  (y'^{(i)} - y^{(i)}) \cdot  y'^{(i)} \cdot (1 - y'^{(i)}) && \text{by \eqref{eq8}}
\end{align} %]]></script>

<p>Training Steps:</p>
<ol>
  <li>Choose an initial vector of parameters  <script type="math/tex">w = (w_1,......w_n)</script>, bias <script type="math/tex">b</script> and learning rate <script type="math/tex">\eta</script>.</li>
  <li>Repeat for predifined epoch such that approximate minimum <script type="math/tex">J</script> loss is obtained:
    <ol>
      <li>Evaluate and store <script type="math/tex">y'^{(i)}</script> for all <script type="math/tex">i = 1,2,3...m</script> training examples by using equation <script type="math/tex">\eqref{eq2}</script></li>
      <li>Update bias, <script type="math/tex">b = b - \eta \cdot  \frac{1}{m}\sum_{i=1}^{m}  (y'^{(i)} - y^{(i)}) \cdot  y'^{(i)} \cdot (1 - y'^{(i)})</script></li>
      <li>For <script type="math/tex">j = 1,2,.....n</script> in <script type="math/tex">w</script> :
        <ol>
          <li>Update, <script type="math/tex">w_j = w_j - \eta \cdot  \frac{1}{m}\sum_{i=1}^{m}  (y'^{(i)} - y^{(i)}) \cdot  y'^{(i)} \cdot (1 - y'^{(i)}) \cdot  x_j^{(i)}</script></li>
        </ol>
      </li>
    </ol>
  </li>
</ol>

<p>Code snippet of above steps:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    
    #Accumulate gradient with respect to bias and weights
    grad_bias = 0
    grad_w = np.zeros(len(W))
    for i in range(X_train.shape[0]):        
        grad_bias += (YP[i] - y_train[i])*(YP[i])*(1-YP[i]) #dJ/db
        for j in range(len(W)):
            #dJ/dW_j
            grad_w[j] += (YP[i] - y_train[i])*(YP[i])*(1-YP[i])*(X_train[i][j])
        
    #Update bias
    bias = bias - grad_bias*lr/X_train.shape[0]    
    
    #Update weights    
    for j in range(len(W)):
        W[j] = W[j] - grad_w[j]*lr/X_train.shape[0]

</code></pre>
</div>

<h4 id="code"><a href="https://github.com/rakesh-malviya/MLCodeGems/blob/master/notebooks/Neural_networks/2-neural-networks-part-1-logistic-regression-least-square-error.ipynb">Code</a></h4>

<p><a href="https://github.com/rakesh-malviya/MLCodeGems/blob/master/notebooks/Neural_networks/2-neural-networks-part-1-logistic-regression-least-square-error.ipynb">Here</a> is the python implementation of the above article.</p>

<h4 id="stochastic-gradient-descent-sgd">Stochastic gradient descent, SGD</h4>
<p>When training data size <script type="math/tex">m</script> is large we choose <script type="math/tex">% <![CDATA[
m' < m %]]></script>  of batch size. We divide our training data into batches of size <script type="math/tex">m'</script>. We update weights and bias for each batch as follows:</p>
<ol>
  <li>Choose an initial vector of parameters  <script type="math/tex">w = (w_1,......w_n)</script>, bias <script type="math/tex">b</script> and learning rate <script type="math/tex">\eta</script>.</li>
  <li>Divide training data into batches of size <script type="math/tex">m'</script></li>
  <li>Repeat for predifined epoch such that approximate minimum <script type="math/tex">J</script> loss is obtained:
    <ol>
      <li>Repeat for each batch:
        <ol>
          <li>Evaluate and store <script type="math/tex">y'^{(i)}</script> for all <script type="math/tex">i = 1,2,3...m</script> training examples by using equation <script type="math/tex">\eqref{eq2}</script></li>
          <li>Update bias, <script type="math/tex">b = b - \eta \cdot  \frac{1}{m'}\sum_{i=1}^{m'}  (y'^{(i)} - y^{(i)}) \cdot  y'^{(i)} \cdot (1 - y'^{(i)})</script></li>
          <li>For <script type="math/tex">j = 1,2,.....n</script> in <script type="math/tex">w</script> : Update, <script type="math/tex">w_j = w_j - \eta \cdot  \frac{1}{m'}\sum_{i=1}^{m'}  (y'^{(i)} - y^{(i)}) \cdot  y'^{(i)} \cdot (1 - y'^{(i)}) \cdot  x_j^{(i)}</script></li>
        </ol>
      </li>
    </ol>
  </li>
</ol>

<h5 id="advantages-of-sgd">Advantages of SGD</h5>
<ol>
  <li>Much faster than normal gradient descent</li>
  <li>Better choice when whole training data cannot fit into the RAM (available memory) of the system</li>
</ol>

<h2 id="references">References:</h2>
<ol>
  <li>http://cs229.stanford.edu/notes</li>
</ol>

<h2 id="previous-posts">Previous Posts:</h2>
<p><a href="/2017/08/15/word2vec-basics.html">“1. Word2vec Part 1: Basics”</a></p>

</div>
<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.10";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
        <div class="fb-share-button" data-href="/2017/08/25/2-neural-networks-part-1-logistic-regression-least-square-error.html" data-layout="button_count" data-size="small" data-mobile-iframe="true"><a class="fb-xfbml-parse-ignore" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdevelopers.facebook.com%2Fdocs%2Fplugins%2F&amp;src=sdkpreparse">Share</a></div>

        <a href="https://twitter.com/share" class="twitter-share-button" data-show-count="false">Tweet</a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

        <!-- Place this tag in your head or just before your close body tag. -->
        <script src="https://apis.google.com/js/platform.js" async defer></script>
        <!-- Place this tag where you want the share button to render. -->
        <div class="g-plus" data-action="share"></div>
        <hr/>


<script id="dsq-count-scr" src="//rakesh-malviya-blog.disqus.com/count.js" async></script>
<div id="disqus_thread"></div>
<script>
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://rakesh-malviya-blog.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>                            


  </div>
  <div class="footer">
  |<a href="/"> ~ </a>|
 </div> 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-106693130-1', 'auto');
  ga('send', 'pageview');

</script>

</body>
</html>
